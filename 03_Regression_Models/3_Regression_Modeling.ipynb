{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3. Regression Modeling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Table of Contents*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Data Cleaning](../01_Data_Cleaning/1_Data_Cleaning.ipynb)\n",
    "2. [EDA and Feature Engineering](../02_Exploratory_Data_Analysis/2_Exploratory_Data_Analysis.ipynb)\n",
    "3. [**Regression Modeling**](./3_Regression_Modeling.ipynb)\n",
    "4. [Time Series](../04_Time_Series_Analysis/4_Time_Series.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Library Imports**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys # Provides a way of using operating system dependent functionality\n",
    "import os  # For interacting with the operating system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third-party imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  # For creating visualizations\n",
    "import numpy as np  # For numerical computations\n",
    "import pandas as pd  # For data manipulation and analysis\n",
    "import seaborn as sns  # For high-level data visualization\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import RFECV, mutual_info_regression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import (train_test_split, GridSearchCV, cross_val_score, KFold)\n",
    "from sklearn.inspection import plot_partial_dependence, permutation_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local application imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the absolute path of the parent directory of the script's grandparent directory\n",
    "# This is useful for module importation from a different directory structure\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "sys.path.insert(0, parent_dir)\n",
    "\n",
    "# Local application imports\n",
    "from utils import func_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **File Importation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the absolute path to the directory containing the current script\n",
    "script_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    "# Construct the path to the data file\n",
    "data_path = os.path.join(script_dir, '01_Data_Cleaning', '1_cleaned_melb_data.csv')\n",
    "\n",
    "# Load dataset containing cleaned Melbourne housing data\n",
    "melb_data = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Feature Selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify categorical features for dummy variable creation.\n",
    "categorical_features = [\n",
    "    'Postcode', 'Suburb', 'Regionname', 'CouncilArea', 'Type', 'SellerG',\n",
    "    'Method', 'Year', 'Month'\n",
    "]\n",
    "\n",
    "# Create dummy variables for categorical features and ensure column names are strings.\n",
    "melb_fs_df = func_utils.concat_dummies(melb_data, categorical_features)\n",
    "melb_fs_df.columns = melb_fs_df.columns.astype(str)\n",
    "\n",
    "# Define columns to exclude from the feature set.\n",
    "excluded_columns = [\n",
    "    'Address', 'Postcode', 'Suburb', 'Regionname', 'CouncilArea', 'Type',\n",
    "    'SellerG', 'Method', 'Date', 'Year', 'Month'\n",
    "]\n",
    "\n",
    "# Prepare the feature matrix (X) and target vector (y).\n",
    "X_fs = melb_fs_df.drop(columns='Price')\n",
    "y_fs = melb_fs_df['Price']\n",
    "\n",
    "# Split the dataset into training and test sets with a test size of 20% and a fixed random state for reproducibility.\n",
    "X_train_fs, X_test_fs, y_train_fs, y_test_fs = train_test_split(\n",
    "    X_fs, y_fs, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutual Information (MI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Mutual Information (MI) scores to select informative features.\n",
    "mi_scores = mutual_info_regression(X_train_fs, y_train_fs)\n",
    "mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X_train_fs.columns)\n",
    "mi_scores = mi_scores.sort_values(ascending=False)\n",
    "print(mi_scores.head(100).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimination (RFE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a RandomForestRegressor as the estimator for RFE.\n",
    "estimator = RandomForestRegressor(n_jobs=-1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply RFECV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cross-validation strategy\n",
    "cv_strategy = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize RFECV with increased step size and simplified model\n",
    "rfecv = RFECV(estimator, step=1, cv=cv_strategy, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# Fit RFECV\n",
    "rfecv.fit(X_train_fs, y_train_fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review the Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the optimal number of features and the best features.\n",
    "print(\"Optimal number of features: \", rfecv.n_features_)\n",
    "print(\"Best features: \", X_train_fs.columns[rfecv.support_])\n",
    "\n",
    "# Get the feature rankings\n",
    "feature_rankings = rfecv.ranking_\n",
    "\n",
    "# Create a series with feature names and their corresponding rankings\n",
    "ranking_series = pd.Series(feature_rankings, index=X_train_fs.columns)\n",
    "\n",
    "# Sort the series to have the highest ranking features at the top\n",
    "sorted_ranking_series = ranking_series.sort_values()\n",
    "\n",
    "# Filter the series to get only features with rank 1\n",
    "top_features = sorted_ranking_series[sorted_ranking_series == 1].index.tolist()\n",
    "\n",
    "print(top_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the CV Score vs. Number of Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the CV score as a function of the number of features.\n",
    "if hasattr(rfecv, \"cv_results_\"):\n",
    "    scores = rfecv.cv_results_['mean_test_score']\n",
    "    plt.figure(figsize=(12, 6))  # You can adjust the figure size to your preference\n",
    "    plt.xlabel(\"Number of features selected\")\n",
    "    plt.ylabel(\"Cross-validation score (neg_mean_squared_error)\")\n",
    "    plt.plot(range(1, len(scores) + 1), scores, marker='o', markersize=3)  # Add marker for each point\n",
    "    plt.grid(True)  # Add gridlines for better precision in viewing\n",
    "    plt.title('RFECV - Number of features vs CV Score')\n",
    "    \n",
    "    # Set x-axis ticks to increments of 25\n",
    "    plt.xticks(np.arange(0, len(scores) + 1, 25))\n",
    "    \n",
    "    plt.tight_layout()  # Adjusts plot to ensure everything fits without overlapping\n",
    "    plt.axvline(x=rfecv.n_features_, color='r', linestyle='--', label='Optimal number of features')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Preprocessing for Model Training**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# List of categorical features for dummy variable creation.\n",
    "categorical_features = [\n",
    "    'Postcode', 'Suburb', 'Regionname', 'CouncilArea', 'Type', 'SellerG',\n",
    "    'Method', 'Year', 'Month'\n",
    "]\n",
    "\n",
    "# Creating dummy variables for categorical features and converting column names to strings.\n",
    "melb_predict_data = func_utils.concat_dummies(melb_data, categorical_features)\n",
    "melb_predict_data.columns = melb_predict_data.columns.astype(str)\n",
    "\n",
    "\n",
    "# Define predictive features for model training.\n",
    "predictive_features = []\n",
    "target = 'Price'\n",
    "\n",
    "# Drop rows with missing target variable and prepare the feature matrix (X) and target vector (y).\n",
    "melb_ba_drop = melb_predict_data.dropna(subset=[target])\n",
    "X = melb_ba_drop[predictive_features]\n",
    "y = melb_ba_drop[target]\n",
    "\n",
    "# Split the dataset into training and test sets with a 20% test size and set a random state for reproducibility.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **GridSearchCV for Random Forest**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': list(range(50, 500, 50)),\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'min_samples_split': list(range(2, 20, 2))\n",
    "}\n",
    "\n",
    "# Execute grid search to find the best model parameters.\n",
    "grid_search = GridSearchCV(estimator, param_grid, cv=5, scoring='neg_mean_squared_error', verbose=2, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and score.\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters:\", best_params)\n",
    "print(\"Best score (MSE):\", -grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Random Forest Model Fitting**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Initialize the RandomForestRegressor with specified hyperparameters.\n",
    "random_f_model = RandomForestRegressor(\n",
    "    n_estimators=400, max_depth=10, min_samples_split=6,\n",
    "    random_state=42, n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the model to the training data.\n",
    "random_f_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on training and test data.\n",
    "y_train_pred = random_f_model.predict(X_train)\n",
    "y_test_pred = random_f_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model Diagnostics**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R² (R-squared)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# R² for training data\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "\n",
    "# R² for test data\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"R² for training data: {r2_train}\")\n",
    "print(f\"R² for test data: {r2_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Perform 5-fold cross-validation to evaluate the model.\n",
    "cv_scores = cross_val_score(random_f_model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "cv_scores = -cv_scores  # Convert scores to positive\n",
    "\n",
    "# Print cross-validation scores, mean, and standard deviation.\n",
    "print(f\"CV MSE scores: {cv_scores}\")\n",
    "print(f\"CV MSE mean: {cv_scores.mean()}\")\n",
    "print(f\"CV MSE standard deviation: {cv_scores.std()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE Calculation"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Calculate RMSE for both training and test datasets.\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "print(f\"Training RMSE: {train_rmse}\")\n",
    "print(f\"Test RMSE: {test_rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE & MAE Calculation"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Calculate MSE and MAE for both training and test datasets.\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Training MSE: {train_mse}\")\n",
    "print(f\"Test MSE: {test_mse}\")\n",
    "print(f\"\\nTraining MAE: {train_mae}\")\n",
    "print(f\"Test MAE: {test_mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partial Dependence Plots"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Example for features 0 and 1\n",
    "features = [0, 1] # Replace with actual feature indices or names\n",
    "plot_partial_dependence(random_f_model, X_train, features=features)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permutation Feature Importance"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "result = permutation_importance(random_f_model, X_test, y_test, n_repeats=10, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Get importance scores\n",
    "importances = result.importances_mean\n",
    "\n",
    "# Optionally, plot these importances\n",
    "plt.figure()\n",
    "plt.bar(range(X_test.shape[1]), importances)\n",
    "plt.xlabel(\"Feature Index\")\n",
    "plt.ylabel(\"Permutation Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Assuming `X_train` includes both numerical and processed categorical variables.\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Extract feature importances from the model.\n",
    "feature_importances = random_f_model.feature_importances_\n",
    "\n",
    "# Create a Series for the feature importances for easy manipulation and sorting.\n",
    "importances_series = pd.Series(\n",
    "    feature_importances, index=feature_names\n",
    ").sort_values(ascending=False)\n",
    "\n",
    "print(importances_series)\n",
    "\n",
    "'''\n",
    "# Retrieve the top N feature names and their corresponding importance values.\n",
    "top_features_count = 75\n",
    "ind = importances_series.nlargest(top_features_count).index.tolist()\n",
    "vals = importances_series.nlargest(top_features_count).values.tolist()\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
